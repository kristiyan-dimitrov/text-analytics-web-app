{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Label dimensionality reduction\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "# Feature generation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# Based on this post: https://stackoverflow.com/questions/42819460/what-is-the-difference-between-onevsrestclassifier-and-multioutputclassifier-in\n",
    "# it appears that OneVsRestClassifier works the same as MultiOutputClassifier in our case with binary Multi-Label classification.\n",
    "\n",
    "# from sklearn.multioutput import MultiOutputClassifier # For doing One-vs-Rest by training K number of binary classifiers where K = n_classes\n",
    "# # See docs: https://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "# Model Tuning\n",
    "from sklearn.model_selection import ParameterGrid, RandomizedSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import jaccard_score, hamming_loss, zero_one_loss, multilabel_confusion_matrix\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gensim_dictionary.pickle', 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "    \n",
    "with open('tokenized_nostops_descriptions.pickle', 'rb') as f:\n",
    "    tokenized_descriptions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_cats.pickle')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureAgglomeration(n_clusters=20\n",
    "                     , affinity = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sns.heatmap(cosine_similarity(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing features & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = df.description\n",
    "labels = df.iloc[:, 3:]\n",
    "print(raw_features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the tokenized descriptions as entire strings, not lists of tokens\n",
    "def stringify(description):\n",
    "    \n",
    "    return \" \".join(description)\n",
    "\n",
    "pool = multiprocessing.Pool(multiprocessing.cpu_count()) # \n",
    "\n",
    "preprocessed_description_strings = pool.map(stringify, tokenized_descriptions)\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example cleaned string\n",
    "preprocessed_description_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW unigrams\n",
    "count_vectorizer = CountVectorizer(lowercase=False, ngram_range =(1,1), max_df = .5, min_df = 100)\n",
    "unigram_bow_corpus = count_vectorizer.fit_transform(preprocessed_description_strings)\n",
    "unigram_bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW unigrams & bigrams\n",
    "count_vectorizer = CountVectorizer(lowercase=False, ngram_range =(1,2), max_df = .5, min_df = 100)\n",
    "uni_and_bigram_bow_corpus = count_vectorizer.fit_transform(preprocessed_description_strings)\n",
    "uni_and_bigram_bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF unigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=False, ngram_range =(1,1), max_df = .5, min_df = 100)\n",
    "unigram_tfidf_corpus = tfidf_vectorizer.fit_transform(preprocessed_description_strings)\n",
    "unigram_tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF unigrams and bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=False, ngram_range =(1,2), max_df = .5, min_df = 100)\n",
    "uni_and_bigram_tfidf_corpus = tfidf_vectorizer.fit_transform(preprocessed_description_strings)\n",
    "uni_and_bigram_tfidf_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">NOTE: CURRENTLY JUST EXPERIMENTING WITH unigram_bow_corpus </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(df.shape[0])\n",
    "\n",
    "train_indices, test_indices = train_test_split(indices, random_state=42, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train = unigram_bow_corpus[train_indices]\n",
    "y_train = labels.iloc[train_indices, :]\n",
    "\n",
    "X_test = unigram_bow_corpus[test_indices]\n",
    "y_test = labels.iloc[test_indices, :]\n",
    "\n",
    "print('TRAINING DATA')\n",
    "print('FEATURES ', X_train.shape)\n",
    "print('LABELS ', y_train.shape)\n",
    "\n",
    "print('TEST DATA')\n",
    "print('FEATURES ',X_test.shape)\n",
    "print('LABELS ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM - FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">NOTE: Much faster with n_jobs = -1 </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 1.12 s, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 4.14 s, total: 2min 27s\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(random_state=42\n",
    "                            , n_jobs = -1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomCV Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {'n_estimators': [70, 100, 150, 200]\n",
    "           , 'max_depth': [None, 2,5,10]\n",
    "           , 'ccp_alpha': [0, .01, .1]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterGrid at 0x7fc8b7f7c990>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = ParameterGrid(rf_dict);param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42\n",
    "                            , n_jobs = -1\n",
    "                            , verbose = 1\n",
    "                           )\n",
    "\n",
    "# Converts the metric function - jaccard_score - into something that RandomizedSearchCV can use to evaluate a given model\n",
    "jaccard_scorer = make_scorer(jaccard_score, average='micro')\n",
    "\n",
    "best_rf = RandomizedSearchCV(rf\n",
    "                             , rf_dict\n",
    "                             , n_iter=10\n",
    "                             , n_jobs = -1\n",
    "                             , cv=3\n",
    "                             , scoring=jaccard_scorer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW - UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1],\n",
       "                                        'max_depth': [None, 2, 5, 10],\n",
       "                                        'n_estimators': [70, 100, 150, 200]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(unigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150, 'max_depth': None, 'ccp_alpha': 0}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_ # {'n_estimators': 150, 'max_depth': None, 'ccp_alpha': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1917938689619385"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different parameter values that were tried and the corresponding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00252974, 0.        , 0.        , 0.1915055 , 0.        ,\n",
       "       0.02180457, 0.        , 0.19179387, 0.02196535, 0.        ])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the average scores over the 10 iterations (average over the 3 CV folds within a given iteration)\n",
    "best_rf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[2, None, 10, None, 2, 5, 10, None, 5, None],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.cv_results_['param_max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[150, 70, 70, 200, 100, 150, 100, 150, 100, 200],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.cv_results_['param_n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[0, 0.1, 0.01, 0, 0.01, 0, 0.1, 0, 0, 0.1],\n",
       "             mask=[False, False, False, False, False, False, False, False,\n",
       "                   False, False],\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.cv_results_['param_ccp_alpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW - UNIGRAM + BIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1],\n",
       "                                        'max_depth': [None, 2, 5, 10],\n",
       "                                        'n_estimators': [70, 100, 150, 200]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(uni_and_bigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150, 'max_depth': 10, 'ccp_alpha': 0}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06529360773901653"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - Unigram_tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   57.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1],\n",
       "                                        'max_depth': [None, 2, 5, 10],\n",
       "                                        'n_estimators': [70, 100, 150, 200]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(unigram_tfidf_corpus , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150, 'max_depth': None, 'ccp_alpha': 0}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19125782241746278"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - UNIGRAM + BIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': [0, 0.01, 0.1],\n",
       "                                        'max_depth': [None, 2, 5, 10],\n",
       "                                        'n_estimators': [70, 100, 150, 200]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(uni_and_bigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100, 'max_depth': 10, 'ccp_alpha': 0}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06368836514927444"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">It appears that max_depth = None with ccp_alpha=0 is best, but could potentially do with more n_estimators </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking just n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {'n_estimators': [130, 150, 170, 200, 230]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42\n",
    "                            , n_jobs = -1\n",
    "                            , verbose = 1\n",
    "                           )\n",
    "\n",
    "# Converts the metric function - jaccard_score - into something that RandomizedSearchCV can use to evaluate a given model\n",
    "jaccard_scorer = make_scorer(jaccard_score, average='micro')\n",
    "\n",
    "best_rf = RandomizedSearchCV(rf\n",
    "                             , rf_dict\n",
    "                             , n_iter=5\n",
    "                             , n_jobs = -1\n",
    "                             , cv=3\n",
    "                             , scoring=jaccard_scorer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW - UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   50.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': [130, 150, 170, 200,\n",
       "                                                         230]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(unigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1917938689619385"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW - UNIGRAM + BIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 230 out of 230 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': [130, 150, 170, 200,\n",
       "                                                         230]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(uni_and_bigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 230}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19338024490508335"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - Unigram_tfidf_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   48.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': [130, 150, 170, 200,\n",
       "                                                         230]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(unigram_tfidf_corpus , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19125782241746278"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - UNIGRAM + BIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 230 out of 230 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': [130, 150, 170, 200,\n",
       "                                                         230]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf.fit(uni_and_bigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 230}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Random Forest Parameters\n",
    "best_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19480018667613816"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top score\n",
    "best_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">It appears that n_estimators=150 is best for the unigram corpuses, but n_estimators=230 (or potentially larger) for the uni+bigram corpuses </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">Also, the Jaccard Score appears to be a bit better on the uni+bigram corpus, but only a little bit </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Estimator in OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single iteration\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "ovr = OneVsRestClassifier(lr).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13294460641399417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_ovr = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35095874491574663"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(y_test, y_pred_lr_ovr, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVR inside RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dict = {'estimator__C': [2,1,.5,.1,.01,0]} # For clarification why there is \"estimator__\", see this SO post: https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "\n",
    "lr = LogisticRegression( #n_jobs = -1\n",
    "                        random_state = 42\n",
    "                        , verbose = 0\n",
    "                        , max_iter = 1000)\n",
    "\n",
    "ovr = OneVsRestClassifier(lr) #, n_jobs = -1\n",
    "\n",
    "# Converts the metric function - jaccard_score - into something that RandomizedSearchCV can use to evaluate a given model\n",
    "jaccard_scorer = make_scorer(jaccard_score, average='micro')\n",
    "\n",
    "best_lr_ovr = RandomizedSearchCV(ovr\n",
    "                             , lr_dict\n",
    "                             , n_iter=5\n",
    "#                              , n_jobs = -1\n",
    "                             , cv=3\n",
    "                             , scoring=jaccard_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                                              random_state=42)),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.fit(unigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 0.5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3358777980831083"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW UNI+BIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                                              random_state=42)),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.fit(uni_and_bigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 0.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34166566869407355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 245, in fit\n",
      "    for i, column in enumerate(columns))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py\", line 81, in _fit_binary\n",
      "    estimator.fit(X, y)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 1417, in fit\n",
      "    for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/kristiyan/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\", line 759, in _logistic_regression_path\n",
      "    args=(X, target, 1. / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                                              random_state=42)),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.fit(unigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2677553984119441"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF UNI+BIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                                              random_state=42)),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.fit(uni_and_bigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 2}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30901622431582276"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">Best performing appears to be BOW Uni+Bigram corpus with C=0.5 </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Estimator in OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "# Single iteration\n",
    "svm = LinearSVC(random_state=42\n",
    "                , max_iter = 50000\n",
    "                , verbose=1)\n",
    "ovr = OneVsRestClassifier(svm).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0793002915451895"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_ovr = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30012686118715365"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(y_test, y_pred_svm_ovr, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_dict = {'estimator__C': [2,1,.5,.1,.01,0]} # For clarification why there is \"estimator__\", see this SO post: https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "\n",
    "svm = LinearSVC(#n_jobs = -1\n",
    "                random_state = 42\n",
    "                , verbose = 1\n",
    "                , max_iter = 50000)\n",
    "\n",
    "ovr = OneVsRestClassifier(svm, n_jobs = -1) #\n",
    "\n",
    "# Converts the metric function - jaccard_score - into something that RandomizedSearchCV can use to evaluate a given model\n",
    "jaccard_scorer = make_scorer(jaccard_score, average='micro')\n",
    "\n",
    "best_svm_ovr = RandomizedSearchCV(ovr\n",
    "                             , svm_dict\n",
    "                             , n_iter=5\n",
    "                             , n_jobs = -1\n",
    "                             , cv=3\n",
    "                             , scoring=jaccard_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LinearSVC(max_iter=50000,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1),\n",
       "                                                 n_jobs=-1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.fit(unigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 0.01}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33347006693731074"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW UNI+BIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LinearSVC(max_iter=50000,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1),\n",
       "                                                 n_jobs=-1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.fit(uni_and_bigram_bow_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 0.1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3285471551655335"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF UNIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LinearSVC(max_iter=50000,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1),\n",
       "                                                 n_jobs=-1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.fit(unigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35970803324115347"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF UNI+BIGRAM CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=OneVsRestClassifier(estimator=LinearSVC(max_iter=50000,\n",
       "                                                                     random_state=42,\n",
       "                                                                     verbose=1),\n",
       "                                                 n_jobs=-1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'estimator__C': [2, 1, 0.5, 0.1, 0.01,\n",
       "                                                         0]},\n",
       "                   scoring=make_scorer(jaccard_score, average=micro))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.fit(uni_and_bigram_tfidf_corpus, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 1}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36267199408424333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_ovr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">Best performing appears to be TFIDF Uni+Bigram corpus with C=1 </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">Also nice that LinearSVC appears to train fairly fast</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC - Radial Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Estimator in OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "# Single iteration\n",
    "svm = SVC(random_state=42\n",
    "          , max_iter = -1 # -1 for no limit.\n",
    "          , verbose=1\n",
    "          , kernel = 'rbf'\n",
    "           )\n",
    "ovr = OneVsRestClassifier(svm).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14110787172011663"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_ovr = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2650083963056255"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_score(y_test, y_pred_svm_ovr, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">Trains quite slow</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3430, 83)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXACT MATCH RATION:  0.11924198250728862\n",
      "JACCARD SCORE average=micro:  0.21248283873693105\n",
      "JACCARD SCORE average=weighted:  0.20345546360720523\n",
      "JACCARD SCORE average=samples:  0.2668857988464402\n",
      "HAMMING LOSS :  0.026193403351013382\n",
      "ZERO-ONE LOSS :  0.8807580174927114\n"
     ]
    }
   ],
   "source": [
    "print(\"EXACT MATCH RATION: \", rf.score(X_test, y_test))\n",
    "print(\"JACCARD SCORE average=micro: \", jaccard_score(y_test, y_pred_rf, average='micro'))\n",
    "print(\"JACCARD SCORE average=weighted: \", jaccard_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(\"JACCARD SCORE average=samples: \", jaccard_score(y_test, y_pred_rf, average='samples'))\n",
    "print(\"HAMMING LOSS : \", hamming_loss(y_test, y_pred_rf))\n",
    "print(\"ZERO-ONE LOSS : \", zero_one_loss(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(steps, rewards_lst[0], \"-\", label=\"First Trial\")\n",
    "plt.plot(steps, np.mean(rewards_lst[:5],axis=0), \"-\", label=\"Avg. First 5 Trials\")\n",
    "plt.plot(steps, np.mean(rewards_lst,axis=0), \"-\", label=\"Avg. First 10 Trials\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel(\"Average Reward\", fontsize = 20)\n",
    "plt.xlabel(\"Number of Steps\")\n",
    "plt.title(\"Average Reward over 100,000 steps for 1, 5, and 10 trials\", fontsize = 30)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum example of using a classifier for Multi-Label classification in a One-vs-Rest STrategy\n",
    "\"This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification\"\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html#sklearn.multioutput.MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape= (100, 20)\n",
      "X \n",
      " [[3. 6. 1. ... 1. 5. 0.]\n",
      " [3. 5. 5. ... 1. 1. 1.]\n",
      " [3. 3. 5. ... 0. 2. 1.]\n",
      " ...\n",
      " [3. 7. 3. ... 2. 4. 2.]\n",
      " [7. 2. 1. ... 1. 1. 1.]\n",
      " [3. 5. 3. ... 1. 2. 4.]]\n",
      "y.shape= (100, 3)\n",
      "y \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "X, y = make_multilabel_classification(n_samples=100 # Number of rows in X & y\n",
    "                                      , n_features=20 # Number of features in X\n",
    "                                      , n_classes=3 # Number of columns in y\n",
    "                                      , n_labels=2 # Supposed to be the number of unique values for the classes in y, but doesn't change for some reason\n",
    "                                      , random_state=0)\n",
    "print(\"X.shape=\", X.shape)\n",
    "print('X \\n', X)\n",
    "print(\"y.shape=\", y.shape)\n",
    "print('y \\n', y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultiOutputClassifier(KNeighborsClassifier()).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True data for last two observations\n",
    "y[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for the last two observations in X\n",
    "clf.predict(X[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1.],\n",
       "        [0., 1.]]),\n",
       " array([[0. , 1. ],\n",
       "        [0.2, 0.8]]),\n",
       " array([[0.6, 0.4],\n",
       "        [0.4, 0.6]])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction probabilities\n",
    "# We have n_classes (in this case 3) n_samples x n_labels matrices(where n_labels appears to be always 2)\n",
    "# In other words, the first matrix gives us the probabilities for 0 or 1 for the first class\n",
    "clf.predict_proba(X[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above how all the numbers in the right column are larger.  \n",
    "This corresponds to the fact taht in the predictions, all the predictions are 1\n",
    "EXCEPT the one for the first observation in the 3rd column.  \n",
    "This is correct, because if we look at the _third_ matrix above, we will see that the first row for the first observation has a higher probability for the label 0 (prob = .6) as opposed to the prob for the label 1 (prob = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.predict(X[-2:]).shape\n",
    "y[-2:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OneVsRestClassifier - Appears to be the same as MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# Based on this post: https://stackoverflow.com/questions/42819460/what-is-the-difference-between-onevsrestclassifier-and-multioutputclassifier-in\n",
    "# it appears that OneVsRestClassifier works the same as MultiOutputClassifier in our case with binary Multi-Label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(KNeighborsClassifier()).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.predict(X[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 1. , 0.4],\n",
       "       [1. , 1. , 0.4],\n",
       "       [1. , 0.8, 0.6]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.predict_proba(X[-3:]) # This gives the same values as the MultiOutPut Classifier but a bit clearer\n",
    "# Each row refers to a specific observation and each column is just the probability of a positive response for that observation for that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.score(X[-3:], y[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring success with Exact Match Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance on entire dataset - this is the EXACT MATCH RATIO!\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the docstring:\n",
    "# In multilabel classification, this function computes subset accuracy:\n",
    "# the set of labels predicted for a sample must *exactly* match the\n",
    "# corresponding set of labels in y_true.\n",
    "\n",
    "# In other words, this is the EXACT MATCH RATIO!\n",
    "\n",
    "accuracy_score(y[-2:], clf.predict(X[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It produces the same results as:\n",
    "clf.score(X[-2:], y[-2:])\n",
    "\n",
    "# From the source code, this is equivalent to:\n",
    "np.mean(np.all(y[-2:] == clf.predict(X[-2:]), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative measures of success other than EXACT MATCH RATIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Score - Measures positive matches\n",
    "For binary classification this formula is clearest and simplest: https://en.wikipedia.org/wiki/Jaccard_index#Similarity_of_asymmetric_binary_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels \n",
      " [[0 1 1]\n",
      " [1 1 1]\n",
      " [1 0 1]]\n",
      "Predicted labels \n",
      " [[0 1 0]\n",
      " [1 1 0]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"True labels \\n\", y[-3:])\n",
    "print(\"Predicted labels \\n\", clf.predict(X[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.66666667, 0.33333333])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If None, the scores for each class are returned.\n",
    "# i.e. this does column-wise jaccard score\n",
    "jaccard_score(y[-3:], clf.predict(X[-3:]), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "jaccard_score(y[-3:], clf.predict(X[-3:]), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "jaccard_score(y[-3:], clf.predict(X[-3:]), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.619047619047619"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate metrics for each label, and find their average, weighted by support \n",
    "# (the number of true instances for each label). This alters macro to account for label imbalance.\n",
    "jaccard_score(y[-3:], clf.predict(X[-3:]), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611111111111111"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n",
    "jaccard_score(y[-3:], clf.predict(X[-3:]), average='samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming Loss - Measures proportion of labels correctly classified\n",
    "The Hamming loss is the fraction of labels that are incorrectly predicted.  \n",
    "\n",
    "In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does not entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes only the individual labels.\n",
    "\n",
    "The Hamming loss is upperbounded by the subset zero-one loss, when normalize parameter is set to True. It is always between 0 and 1, lower being better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr.predict(X[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "hamming_loss(y[-2:], ovr.predict(X[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-One Loss - Number of things incorrectly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "y_pred = [1, 2, 3, 4]\n",
    "y_true = [2, 2, 3, 4]\n",
    "zero_one_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_loss(y_true, y_pred, normalize=False) # A LOT MORE UNFORGIVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_loss(np.array([[0, 1], [1, 1], [1, 0]]), np.ones((3, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outpush below is the same type as for MultiOutputClassification.  \n",
    "i.e. each matrix is a 2x2 confusion matrix for the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 1],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 1, 1],\n",
    "                   [0, 1, 0, 1]])\n",
    "y_pred = np.array([[1, 0, 0, 1],\n",
    "                   [0, 1, 1, 0]])\n",
    "multilabel_confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0],\n",
       "        [1, 2]],\n",
       "\n",
       "       [[1, 1],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 1, 1],\n",
    "                   [0, 1, 0, 1]])\n",
    "y_pred = np.array([[1, 0, 0, 1],\n",
    "                   [0, 1, 1, 0]])\n",
    "multilabel_confusion_matrix(y_true, y_pred, samplewise=True) # This does it ROW BY ROW instead of for each label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
